{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd94fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "from typing import Callable, Optional\n",
    "import pyarrow.dataset as ds, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas.api.types as ptypes\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from tabulate import tabulate\n",
    "\n",
    "START_SLOT = 370656000  # Start of epoch 858\n",
    "END_SLOT = 377135999  # End of epoch 872\n",
    "TX_TYPES = [\"frontRun\", \"backRun\", \"victim\", \"transfer\"]\n",
    "ATTACKER_TX_TYPES = [\"frontRun\", \"backRun\", \"transfer\"]\n",
    "EPS_WIN = 1e-5\n",
    "\n",
    "start = START_SLOT\n",
    "end = END_SLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rows(df, idx, show_addr=False):\n",
    "    df_print = df.iloc[idx]\n",
    "    if not show_addr:\n",
    "        df_print = df_print.drop(columns=[\"signer_addresses\", \"signer_addresses_str\"])\n",
    "    print(tabulate(df_print, headers='keys', tablefmt='psql'))\n",
    "\n",
    "def print_df(df, top_n=5):\n",
    "    print(tabulate(df.head(top_n), headers='keys', tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887da190",
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_PATH = \"data/parquet_out\"\n",
    "SANDWICH_STAT_PATH = \"data/sandwich_stat.csv\"\n",
    "\n",
    "# 1. load sandwich transaction data\n",
    "start_time = time.time()\n",
    "\n",
    "sandwiches_txs = ds.dataset(TX_PATH, format=\"parquet\")\n",
    "sandwiches_txs = sandwiches_txs.to_table().to_pandas()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "print(f\"Query took {elapsed:.2f} seconds\")\n",
    "\n",
    "# 2. load sandwich statistics \n",
    "sandwich_stat = pd.read_csv(SANDWICH_STAT_PATH)\n",
    "\n",
    "# 3. print basic information\n",
    "print(f\"Block {sandwiches_txs['tx_slot'].min()} - Block {sandwiches_txs['tx_slot'].max()}\")\n",
    "print(f\" - Number of transactions: {len(sandwiches_txs)}\")\n",
    "print(f\" - Number of sandwiches: {sandwiches_txs['sandwichId'].nunique()}\")\n",
    "print(f\" - Number of victims: {sandwiches_txs[sandwiches_txs['type']=='victim']['signer'].nunique()}\")\n",
    "print(f\" - Number of unique victim transactions: {sandwiches_txs[sandwiches_txs['type']=='victim']['signature'].nunique()}\")\n",
    "print(f\" - Number of victim transactions: {len(sandwiches_txs[sandwiches_txs['type']=='victim']['signature'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f190d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "victims = sandwiches_txs[sandwiches_txs['type'] == 'victim']\n",
    "\n",
    "# Count how many distinct sandwich attacks each victim transaction experienced\n",
    "victim_attack_counts = (\n",
    "    victims.groupby('signature')['sandwichId']\n",
    "    .nunique()\n",
    "    .reset_index(name='num_sandwiches')\n",
    ")\n",
    "\n",
    "victim_attack_counts.sort_values(by='num_sandwiches', ascending=False, inplace=True)\n",
    "\n",
    "# Compute the average number of sandwich attacks per victimized transaction\n",
    "avg_sandwiches_per_victim = victim_attack_counts['num_sandwiches'].mean()\n",
    "\n",
    "print(f\"Average sandwiches per victimized tx: {avg_sandwiches_per_victim:.3f}\")\n",
    "\n",
    "# Average Victim Count\n",
    "victim_counts = (\n",
    "    victims.groupby('sandwichId')['signature']   # group by sandwich and count distinct victims\n",
    "    .nunique()\n",
    "    .reset_index(name='num_victims')\n",
    ")\n",
    "\n",
    "# Sort and print top 10\n",
    "victim_counts = victim_counts.sort_values(by='num_victims', ascending=False)\n",
    "\n",
    "# Average number of victims per sandwich attack\n",
    "avg_victims_per_sandwich = victim_counts['num_victims'].mean()\n",
    "print(f\"Average victims per sandwich: {avg_victims_per_sandwich:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_sandwiches = sandwiches_txs[(sandwiches_txs['relativeDiffB'] > -1e-6) & (sandwiches_txs['relativeDiffB'] < 1e-6)]['sandwichId'].unique().tolist()\n",
    "print(f\"Number of perfect sandwiches: {len(perfect_sandwiches)} ({len(perfect_sandwiches) / len(sandwich_stat) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_address_map = {\n",
    "    'SOL': 'SOL',\n",
    "    'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v': 'USDC',\n",
    "    'Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB': 'USDT',\n",
    "    'USD1ttGY1N17NEEHLmELoaybftRBUSErhqYiQzvEmuB': 'USD1',\n",
    "    '7zoFNf4p3PuFMjL38TPZ4MsGBzofXQfoYPy7aWdBUG1S': 'DS Ai',\n",
    "    'JUPyiwrYJFskUPiHa7hkeR8VUtAeFoSYbKedZNsDvCN': 'JUP',\n",
    "    '7NvJpPcxaNaUqxjLSkx7gHHo9zkmDTA3YTvwB5hw7gpe': 'GROKAI',\n",
    "    'AjkYmQPU1vg9oWQ2oJV3cxKJD3i6C8Xt73yyzLXYZ6FE': '$GROKAI',\n",
    "}\n",
    "sandwich_stat['tokenA_label'] = sandwich_stat['tokenA'].map(token_address_map).fillna(sandwich_stat['tokenA'])\n",
    "\n",
    "token_stats = (\n",
    "    sandwich_stat.groupby('tokenA_label', as_index=False)\n",
    "    .agg(sandwich_count=('sandwichId', 'count'),\n",
    "         total_profit=('profit_in_usd', 'sum'))\n",
    ")\n",
    "total_sandwiches = token_stats['sandwich_count'].sum()\n",
    "token_stats['percentage'] = token_stats['sandwich_count'] / total_sandwiches * 100\n",
    "\n",
    "top_5_tokens = token_stats.sort_values('sandwich_count', ascending=False).head(5)\n",
    "print_df(top_5_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33bca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sandwich_stat[\"distance\"] = np.where(\n",
    "    sandwich_stat[\"distance_type\"] != \"cross_block\",\n",
    "    sandwich_stat[\"inblock_distance\"],\n",
    "    sandwich_stat[\"crossblock_distance\"],\n",
    ")\n",
    "\n",
    "atomic_sandwiches = sandwich_stat[sandwich_stat['distance_type'] == 'inblock_consec']\n",
    "non_atomic_sandwiches = sandwich_stat[sandwich_stat['distance_type'] != 'inblock_consec']\n",
    "non_atomic_inblock_sandwiches = non_atomic_sandwiches[non_atomic_sandwiches['distance_type'] == 'inblock_non_consec']\n",
    "non_atomic_crossblock_sandwiches = non_atomic_sandwiches[non_atomic_sandwiches['distance_type'] == 'cross_block']\n",
    "\n",
    "print(f\"\\nAtomic Sandwich - \\n\\tCount: {len(atomic_sandwiches)}, \\tShare: {len(atomic_sandwiches) / len(sandwich_stat):.3f} \\\n",
    "        \\n\\tProfit: {atomic_sandwiches['profit_in_usd'].sum()}, \\tAverage Profit: {atomic_sandwiches['profit_in_usd'].sum() / len(atomic_sandwiches):.3f} \\\n",
    "        \\n\\tAverage Distance: {atomic_sandwiches['distance'].mean()}\")\n",
    "\n",
    "\n",
    "print(f\"\\nNon-Atomic Sandwich - \\n\\tCount: {len(non_atomic_sandwiches)}, \\tShare: {len(non_atomic_sandwiches) / len(sandwich_stat):.3f} \\\n",
    "        \\n\\tProfit: {non_atomic_sandwiches['profit_in_usd'].sum()}, \\tAverage Profit: {non_atomic_sandwiches['profit_in_usd'].sum() / len(non_atomic_sandwiches):.3f} \\\n",
    "        \\n\\tAverage Distance: {non_atomic_sandwiches['distance'].mean()}\")\n",
    "\n",
    "\n",
    "print(f\"\\nNon-Atomic Inblock Sandwich - \\n\\tCount: {len(non_atomic_inblock_sandwiches)}, \\tShare: {len(non_atomic_inblock_sandwiches) / len(sandwich_stat):.3f} \\\n",
    "        \\n\\tProfit: {non_atomic_inblock_sandwiches['profit_in_usd'].sum()}, \\tAverage Profit: {non_atomic_inblock_sandwiches['profit_in_usd'].sum() / len(non_atomic_sandwiches):.3f} \\\n",
    "        \\n\\tAverage Distance: {non_atomic_inblock_sandwiches['distance'].mean()}\")\n",
    "\n",
    "print(f\"\\nNon-Atomic Crossblock Sandwich - \\n\\tCount: {len(non_atomic_crossblock_sandwiches)}, \\tShare: {len(non_atomic_crossblock_sandwiches) / len(sandwich_stat):.3f} \\\n",
    "        \\n\\tProfit: {non_atomic_crossblock_sandwiches['profit_in_usd'].sum()}, \\tAverage Profit: {non_atomic_crossblock_sandwiches['profit_in_usd'].sum() / len(non_atomic_sandwiches):.3f} \\\n",
    "        \\n\\tAverage Distance: {non_atomic_crossblock_sandwiches['distance'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a53b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_connect import get_client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def load_env():\n",
    "    load_dotenv(dotenv_path=\".env\")\n",
    "    return {\n",
    "        \"host\": os.getenv(\"CLICKHOUSE_HOST\"),\n",
    "        \"port\": int(os.getenv(\"CLICKHOUSE_PORT\")),\n",
    "        \"username\": os.getenv(\"CLICKHOUSE_USERNAME\"),\n",
    "        \"password\": os.getenv(\"CLICKHOUSE_PASSWORD\"),\n",
    "    }\n",
    "\n",
    "# Load credentials from .env\n",
    "config = load_env()\n",
    "# Initialize ClickHouse client\n",
    "client = get_client(\n",
    "    host=config[\"host\"],\n",
    "    port=config[\"port\"],\n",
    "    username=config[\"username\"],\n",
    "    password=config[\"password\"],\n",
    ")\n",
    "\n",
    "def query_slot_leader_in_DB(start_slot=0, end_slot=500000000):\n",
    "    \"\"\"\n",
    "    Query the ClickHouse DB to get slot info stored\n",
    "    \"\"\"\n",
    "    if start_slot < START_SLOT:\n",
    "        print(\"Warning: start_slot is before the earliest valid slot in DB.\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        slot,\n",
    "        leader\n",
    "    FROM solwich.slot_leaders\n",
    "    WHERE slot BETWEEN {start_slot} AND {end_slot}\n",
    "    ORDER BY slot ASC\n",
    "    \"\"\"\n",
    "    result = client.query(query)\n",
    "    df = pd.DataFrame(result.result_rows, columns=result.column_names)\n",
    "    return df\n",
    "\n",
    "slot_leader_df = query_slot_leader_in_DB(start, end)\n",
    "slot_leader_df = slot_leader_df.drop_duplicates(subset=['slot', 'leader'])\n",
    "slot_leader_df.to_csv('data/slot_leader.csv', index=False)\n",
    "\n",
    "total_vol = pd.read_csv('data/slot_tx.csv')\n",
    "total_vol = total_vol.merge(\n",
    "    sandwiches_txs[['tx_slot', 'timestamp']],\n",
    "    how='left',\n",
    "    left_on='slot',\n",
    "    right_on='tx_slot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# This function plots two layers of time-series summaries:\n",
    "# The upper chart shows hourly profit in USD and hourly sandwich volume on dual y-axes.\n",
    "# The lower chart shows daily user transaction volume, daily sandwich volume, and the percentage change of SOL price, also on dual y-axes.\n",
    "def plot_time_summary_line(\n",
    "    df: pd.DataFrame,\n",
    "    sol_price_csv: str,\n",
    "    interval_hours: int = 1,\n",
    "    smooth_window: int = None,\n",
    "    figsize=(12, 8),\n",
    "    save_path=None,\n",
    "    dpi: int = 600,\n",
    "):\n",
    "\n",
    "    # Convert timestamps, remove invalid entries, and bucket into hourly intervals\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "    df = df.dropna(subset=[\"timestamp\"])\n",
    "    df[\"time_bucket\"] = df[\"timestamp\"].dt.floor(f\"{interval_hours}H\")\n",
    "\n",
    "    # Aggregate profit and sandwich volume by hour\n",
    "    hourly_summary = (\n",
    "        df.groupby(\"time_bucket\", as_index=False)\n",
    "          .agg(total_profit_usd=(\"profit_in_usd\", \"sum\"),\n",
    "               total_volume=(\"sandwichId\", \"count\"))\n",
    "    )\n",
    "    if smooth_window and smooth_window > 1:\n",
    "        hourly_summary[\"profit_smooth\"] = hourly_summary[\"total_profit_usd\"].rolling(smooth_window, min_periods=1).mean()\n",
    "        hourly_summary[\"volume_smooth\"] = hourly_summary[\"total_volume\"].rolling(smooth_window, min_periods=1).mean()\n",
    "    else:\n",
    "        hourly_summary[\"profit_smooth\"] = hourly_summary[\"total_profit_usd\"]\n",
    "        hourly_summary[\"volume_smooth\"] = hourly_summary[\"total_volume\"]\n",
    "\n",
    "    # Aggregate sandwich volume by day\n",
    "    df[\"date\"] = df[\"timestamp\"].dt.date\n",
    "    daily_summary = (\n",
    "        df.groupby(\"date\", as_index=False)\n",
    "          .agg(total_volume=(\"sandwichId\", \"count\"))\n",
    "    )\n",
    "\n",
    "    # Load daily SOL price\n",
    "    sol_price = pd.read_csv(sol_price_csv)\n",
    "    sol_price[\"date\"] = pd.to_datetime(sol_price[\"date\"]).dt.date\n",
    "    daily_summary = pd.merge(daily_summary, sol_price, on=\"date\", how=\"left\")\n",
    "\n",
    "    # Load daily user transaction volume\n",
    "    total_vol[\"date\"] = total_vol[\"timestamp\"].dt.date\n",
    "    daily_vol = (\n",
    "        total_vol.groupby(\"date\", as_index=False)\n",
    "            .agg(total_tx_volume=(\"validTxCount\", \"sum\"))\n",
    "    )\n",
    "    daily_summary = pd.merge(daily_summary, daily_vol, on=\"date\", how='left')\n",
    "\n",
    "    # Compute absolute percentage change of SOL price\n",
    "    daily_summary = daily_summary.sort_values(\"date\")\n",
    "    daily_summary[\"price_diff\"] = abs(daily_summary[\"price\"].pct_change() * 100)\n",
    "    daily_summary[\"price_diff\"] = daily_summary[\"price_diff\"].fillna(0)\n",
    "\n",
    "    # General plot settings\n",
    "    plt.style.use(\"default\")\n",
    "    plt.rcParams.update({\n",
    "        \"font.size\": 15,\n",
    "        \"axes.labelsize\": 14,\n",
    "        \"axes.titlesize\": 17,\n",
    "        \"xtick.labelsize\": 12,\n",
    "        \"ytick.labelsize\": 12,\n",
    "        \"axes.edgecolor\": \"black\",\n",
    "        \"xtick.color\": \"black\",\n",
    "        \"ytick.color\": \"black\",\n",
    "        \"axes.labelcolor\": \"black\",\n",
    "    })\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "\n",
    "    # Colors for the different metrics\n",
    "    color_profit = \"#1f77b4\"\n",
    "    color_volume = \"#2ca02c\"\n",
    "    color_volume_d = \"#ff7f0e\"\n",
    "    color_tx_volume = \"#d62728\"\n",
    "    color_price = \"#ffcc00\"\n",
    "\n",
    "    # Upper chart: hourly profit and hourly sandwich volume\n",
    "    ax1b = ax1.twinx()\n",
    "    ax1b.set_ylabel(\"Hourly Sandwich Volume\", color=\"black\")\n",
    "    ax1b.plot(hourly_summary[\"time_bucket\"], hourly_summary[\"volume_smooth\"],\n",
    "              color=color_volume, lw=3, label=\"Hourly Sandwich Volume\")\n",
    "    \n",
    "    ax1.set_ylabel(\"Hourly Profit (USD)\", color=\"black\")\n",
    "    ax1.plot(hourly_summary[\"time_bucket\"], hourly_summary[\"profit_smooth\"],\n",
    "             color=color_profit, lw=3, label=\"Hourly Profit (USD)\")\n",
    "\n",
    "    # Lower chart: daily transaction volume, daily sandwich volume, and SOL price change\n",
    "    ax2c = ax2.twinx()\n",
    "    ax2c.spines[\"right\"].set_position((\"outward\", 65))\n",
    "    ax2c.set_ylabel(\"Change of SOL Price (%)\", color=\"black\")\n",
    "    ax2c.plot(daily_summary[\"date\"], daily_summary[\"price_diff\"],\n",
    "              color=color_price, lw=3, label=\"SOL Price Change\")\n",
    "    \n",
    "    ax2.set_ylabel(\"Daily Users Tx Volume\", color=\"black\")\n",
    "    ax2.plot(daily_summary[\"date\"], daily_summary[\"total_tx_volume\"],\n",
    "            color=color_tx_volume, lw=3, label=\"Users Tx Volume\")\n",
    "\n",
    "    ax2b = ax2.twinx()\n",
    "    ax2b.set_ylabel(\"Daily Sandwich Volume\", color=\"black\")\n",
    "    ax2b.plot(daily_summary[\"date\"], daily_summary[\"total_volume\"],\n",
    "             color=color_volume_d, lw=3, label=\"Daily Sandwich Volume\")\n",
    "\n",
    "    # X-axis alignment across both charts\n",
    "    t1 = hourly_summary[\"time_bucket\"]\n",
    "    t2 = pd.to_datetime(daily_summary[\"date\"])\n",
    "    all_times = pd.date_range(start=min(t1.min(), t2.min()), end=max(t1.max(), t2.max()), freq=\"D\")\n",
    "    min_time, max_time = all_times.min(), all_times.max()\n",
    "    padding = pd.Timedelta(days=2)\n",
    "    ax1.set_xlim(min_time - padding, max_time + padding)\n",
    "    ax2.set_xlim(min_time - padding, max_time + padding)\n",
    "\n",
    "    # Use integer ticks for y-axes\n",
    "    ax1.yaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "    ax2.yaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "    ax1b.yaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "    ax2b.yaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "    ax2c.yaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "\n",
    "    ax1.set_ylim(bottom=-5000)\n",
    "    ax1b.set_ylim(bottom=-5000)\n",
    "    ax2.set_ylim(bottom=-5e7)\n",
    "    ax2b.set_ylim(bottom=-25000)\n",
    "    ax2c.set_ylim(bottom=-1)\n",
    "\n",
    "    # Draw grid lines based on the left axis of each subplot\n",
    "    x_grid_dates = pd.date_range(min_time, max_time, freq=\"D\")\n",
    "    for ax, axb in [(ax1, ax1b), (ax2, ax2b)]:\n",
    "        for y in ax.get_yticks():\n",
    "            ax.axhline(y=y, color=\"#DDDDDD\", linestyle=\"--\", linewidth=0.7, alpha=0.6, zorder=0)\n",
    "\n",
    "        l, r = ax.get_xlim()\n",
    "        left_dt  = mdates.num2date(l).replace(tzinfo=None)\n",
    "        right_dt = mdates.num2date(r).replace(tzinfo=None)\n",
    "        for x in pd.date_range(left_dt, right_dt, freq=\"D\"):\n",
    "            ax.axvline(x=x, color=\"#DDDDDD\", linestyle=\"--\", linewidth=0.7, alpha=0.6, zorder=0)\n",
    "\n",
    "        ax.grid(False)\n",
    "        axb.grid(False)\n",
    "\n",
    "    # Legend setup\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax1b.get_legend_handles_labels()\n",
    "    lines3, labels3 = ax2.get_legend_handles_labels()\n",
    "    lines4, labels4 = ax2b.get_legend_handles_labels()\n",
    "    lines5, labels5 = ax2c.get_legend_handles_labels()\n",
    "\n",
    "    upper_lines = lines1 + lines2\n",
    "    upper_labels = labels1 + labels2\n",
    "\n",
    "    lower_lines = lines3 + lines4 + lines5\n",
    "    lower_labels = labels3 + labels4 + labels5\n",
    "\n",
    "    fig.legend(\n",
    "        upper_lines,\n",
    "        upper_labels,\n",
    "        loc=\"lower center\",\n",
    "        ncol=2,\n",
    "        bbox_to_anchor=(0.5, -0.01),\n",
    "        fontsize=14,\n",
    "        frameon=True,\n",
    "        facecolor=\"white\",\n",
    "        edgecolor=\"#DDDDDD\",\n",
    "        handlelength=2.5,\n",
    "        columnspacing=1.2,\n",
    "    )\n",
    "\n",
    "    fig.legend(\n",
    "        lower_lines,\n",
    "        lower_labels,\n",
    "        loc=\"lower center\",\n",
    "        ncol=3,\n",
    "        bbox_to_anchor=(0.5, -0.06),\n",
    "        fontsize=14,\n",
    "        frameon=True,\n",
    "        facecolor=\"white\",\n",
    "        edgecolor=\"#DDDDDD\",\n",
    "        handlelength=2.5,\n",
    "        columnspacing=1.2,\n",
    "    )\n",
    "\n",
    "    # Styling for axes\n",
    "    for ax in [ax1, ax1b, ax2, ax2b]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_color(\"black\")\n",
    "        ax.tick_params(colors=\"black\", direction=\"inout\", length=5)\n",
    "\n",
    "    ax2.xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "\n",
    "    # Format y-axis using scientific notation when appropriate\n",
    "    def format_axis(ax):\n",
    "        from matplotlib.ticker import ScalarFormatter, MaxNLocator\n",
    "        formatter = ScalarFormatter(useMathText=True)\n",
    "        formatter.set_powerlimits((-3, 4))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(-3,4))\n",
    "\n",
    "        offset_text = ax.yaxis.get_offset_text()\n",
    "        offset_text.set_fontsize(11)\n",
    "        offset_text.set_color('black')\n",
    "        x, y = offset_text.get_position()\n",
    "        offset_text.set_position((x, y + 0.02))\n",
    "\n",
    "    for a in [ax1, ax1b, ax2, ax2b, ax2c]:\n",
    "        format_axis(a)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(f\"Saved: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return hourly_summary, daily_summary\n",
    "\n",
    "hourly_summary, daily_summary = plot_time_summary_line(\n",
    "    sandwich_stat,\n",
    "    sol_price_csv=\"data/sol_price.csv\",\n",
    "    interval_hours=1,\n",
    "    smooth_window=3,\n",
    "    save_path=\"data/sandwich_line_profit_volume.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62313e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bidirectional_bar_rotated(\n",
    "    grouped, \n",
    "    df_raw, \n",
    "    title, \n",
    "    save_path,\n",
    "    positive_color='#6BAED6',    \n",
    "    negative_color='#F08080',    \n",
    "    profit_line_color=\"#983232\", \n",
    "    volume_line_color=\"#2C2C81\"  \n",
    "):\n",
    "    \"\"\"\n",
    "    Draws a bidirectional bar chart rotated 90 degrees, combined with an average profit line\n",
    "    and a total volume line using a secondary y-axis.\n",
    "    - The x-axis represents distance bins.\n",
    "    - The left y-axis shows average profit (positive and negative bars plus a profit line).\n",
    "    - The right y-axis shows total volume.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare sorted data and extract bins\n",
    "    g = grouped.sort_values('distance_bin').copy()\n",
    "    bins = g['distance_bin'].astype(str).to_numpy()\n",
    "    x_pos = np.arange(len(bins))\n",
    "\n",
    "    # Positive and negative profit values\n",
    "    pos = g['positive'].fillna(0).to_numpy()\n",
    "    neg = g['negative'].fillna(0).to_numpy()\n",
    "\n",
    "    # Average profit across all sandwiches within each distance bin\n",
    "    avg_all = (\n",
    "        df_raw.groupby('distance_bin')['profit_in_usd']\n",
    "        .mean()\n",
    "        .reindex(g['distance_bin'])\n",
    "        .fillna(0)\n",
    "        .to_numpy()\n",
    "    )\n",
    "\n",
    "    # Total volume counted by distinct sandwichId in each bin\n",
    "    total_volume = (\n",
    "        df_raw.groupby('distance_bin')['sandwichId']\n",
    "        .nunique()\n",
    "        .reindex(g['distance_bin'])\n",
    "        .fillna(0)\n",
    "        .to_numpy()\n",
    "    )\n",
    "\n",
    "    # Begin plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "    # Draw positive and negative bars on the left axis\n",
    "    bar_w = 0.55\n",
    "    ax1.bar(x_pos, pos, color=positive_color, width=bar_w,\n",
    "            label='Average Gain', alpha=0.9)\n",
    "    ax1.bar(x_pos, neg, color=negative_color, width=bar_w,\n",
    "            label='Average Loss', alpha=0.9)\n",
    "\n",
    "    # Average profit line\n",
    "    ax1.plot(\n",
    "        x_pos, avg_all, color=profit_line_color, marker='o',\n",
    "        linewidth=1.5, label='Average Profit', alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Left-axis styling\n",
    "    ax1.axhline(0, color='#000000', linewidth=0.8)\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(bins, rotation=30, ha='right', fontsize=12)\n",
    "    ax1.set_xlabel('Distance', fontsize=16)\n",
    "    ax1.set_ylabel('Average Profit (USD)', fontsize=16)\n",
    "    ax1.tick_params(axis='x', labelsize=13)\n",
    "    ax1.tick_params(axis='y', labelsize=13)\n",
    "    ax1.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "    ax1.grid(False, axis='x')\n",
    "    ax1.set_facecolor('#F9FAFB')\n",
    "    ax1.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    # Right axis for total volume\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(\n",
    "        x_pos, total_volume, color=volume_line_color, marker='s',\n",
    "        linewidth=1.5, linestyle='--', label='Total Volume', alpha=0.9\n",
    "    )\n",
    "    ax2.axhline(0, color='black', linewidth=0.8, alpha=0.6)\n",
    "    ax2.set_ylabel('Volume', fontsize=16)\n",
    "    ax2.grid(False)\n",
    "\n",
    "    # Compute axis limits for both sides so that the visual scale is balanced\n",
    "    pos_max = np.nanmax(pos) if len(pos) else 0.0\n",
    "    neg_min = np.nanmin(neg) if len(neg) else 0.0\n",
    "    avg_max = np.nanmax(avg_all) if len(avg_all) else 0.0\n",
    "    avg_min = np.nanmin(avg_all) if len(avg_all) else 0.0\n",
    "    vol_max = np.nanmax(total_volume) if len(total_volume) else 0.0\n",
    "    vol_min = np.nanmin(total_volume) if len(total_volume) else 0.0\n",
    "\n",
    "    upper_left = max(pos_max, avg_max) * 1.2\n",
    "    lower_left = min(neg_min, avg_min) * 1.05\n",
    "\n",
    "    upper_right = max(vol_max, 0) * 1.2\n",
    "    lower_right = min(vol_min, 0) * 1.05\n",
    "\n",
    "    left_ratio = upper_left / abs(lower_left) if lower_left != 0 else 0\n",
    "\n",
    "    if abs(upper_right) > abs(lower_right):\n",
    "        lower_right = -abs(upper_right / left_ratio)\n",
    "    else:\n",
    "        upper_right = abs(lower_right * left_ratio)\n",
    "\n",
    "    ax1.set_ylim(lower_left, upper_left)\n",
    "    ax2.set_ylim(lower_right, upper_right)\n",
    "\n",
    "    # Combine legends and control ordering\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "    handles_dict = dict(zip(labels_1 + labels_2, lines_1 + lines_2))\n",
    "    order = ['Average Gain', 'Average Loss', 'Average Profit', 'Total Volume']\n",
    "\n",
    "    ordered_handles = [handles_dict[o] for o in order if o in handles_dict]\n",
    "    ordered_labels = [o for o in order if o in handles_dict]\n",
    "\n",
    "    ax1.legend(\n",
    "        ordered_handles, ordered_labels,\n",
    "        frameon=False, loc='lower left', ncol=2, fontsize=14\n",
    "    )\n",
    "    \n",
    "    ax1.tick_params(axis='x', labelsize=14)\n",
    "    ax1.tick_params(axis='y', labelsize=14)\n",
    "    ax2.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "    for ax in [ax1, ax2]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('black')\n",
    "            spine.set_linewidth(0.8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72475619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance vs profit\n",
    "df = sandwich_stat\n",
    "\n",
    "print(f\"\\nAverage distance of all sandwiches: {df['distance'].mean()}\")\n",
    "print(f\"Average distance of Non-consec. IB: {sandwich_stat[sandwich_stat['distance_type']=='inblock_non_consec']['inblock_distance'].mean()}\")\n",
    "print(f\"Average distance of Non-consec. IB: {sandwich_stat[sandwich_stat['distance_type']=='cross_block']['crossblock_distance'].mean()}\")\n",
    "print(f\"\\nAverage profit of inblock-non-consec: {df[df['distance_type']=='inblock_non_consec']['profit_in_usd'].mean()}\")\n",
    "print(f\"Average profit of inblock-non-consec: {df[df['distance_type']=='cross_block']['profit_in_usd'].mean()}\")\n",
    "\n",
    "small_dist_consec = sandwich_stat[(sandwich_stat['distance_type']=='inblock_consec') & (sandwich_stat['distance']<=5)]\n",
    "small_dist_non_consec = sandwich_stat[(sandwich_stat['distance_type']!='inblock_consec') & (sandwich_stat['distance']<=5)]\n",
    "print(f\"\\nAverage profit of consecutive sandwich with distance in 1-9: {small_dist_consec['profit_in_usd'].mean()} ({len(small_dist_consec)})\")\n",
    "print(f\"Average profit of non-consecutive sandwich with distance in 1-9: {small_dist_non_consec['profit_in_usd'].mean()} ({len(small_dist_non_consec)})\")\n",
    "\n",
    "distance_bins = [0, 10, 100, 500, 1000, 3000, 6000, 10000, float('inf')]\n",
    "distance_labels = [\n",
    "    '1-9', '10–99', '100-499', '500–999', \n",
    "    '1000–2999','3000–5999', '6000–9999', '≥10000'\n",
    "]\n",
    "\n",
    "df['distance_bin'] = pd.cut(\n",
    "    df['distance'],\n",
    "    bins=distance_bins,\n",
    "    labels=distance_labels,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "grouped_profit = df.groupby(['distance_bin'])['profit_in_usd'].agg(\n",
    "    positive=lambda x: x[x >= 0].mean(),\n",
    "    negative=lambda x: x[x < 0].mean()\n",
    ").reset_index()\n",
    "\n",
    "plot_bidirectional_bar_rotated(\n",
    "    grouped_profit,\n",
    "    df_raw=df,   \n",
    "    title='Average Profit and Total Volume by Distance',\n",
    "    save_path='data/average_profit_volume_by_distance.pdf'\n",
    ")\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evasive Strategies\n",
    "\n",
    "# 1. Changing-signer\n",
    "diff_signer_sandwiches = sandwich_stat[sandwich_stat['signerSame']==False]\n",
    "print(f\"\\nNumber of sandwiches utilizing signer-changing: {len(diff_signer_sandwiches)} ({len(diff_signer_sandwiches) / len(sandwich_stat):.2f})\")\n",
    "print(f\"Atomic: {len(diff_signer_sandwiches[diff_signer_sandwiches['distance_type'] == 'inblock_consec'])} ({len(diff_signer_sandwiches[diff_signer_sandwiches['distance_type'] == 'inblock_consec']) / len(sandwich_stat[sandwich_stat['distance_type']=='inblock_consec']) * 100:.2f}), Profit: {diff_signer_sandwiches[diff_signer_sandwiches['distance_type'] == 'inblock_consec']['profit_in_usd'].sum()}\")\n",
    "print(f\"Non-Atomic: {len(diff_signer_sandwiches[diff_signer_sandwiches['distance_type'] != 'inblock_consec'])} \\\n",
    "        ({len(diff_signer_sandwiches[diff_signer_sandwiches['distance_type'] != 'inblock_consec']) / len(sandwich_stat[sandwich_stat['distance_type'] != 'inblock_consec'])}), \\\n",
    "        Profit: {diff_signer_sandwiches[diff_signer_sandwiches['distance_type'] != 'inblock_consec']['profit_in_usd'].sum()}\")\n",
    "print(f\"Total Profit: {diff_signer_sandwiches['profit_in_usd'].sum()}\")\n",
    "\n",
    "diff_signer_sandwiches_with_transfer_list = sandwiches_txs[sandwiches_txs['type']=='transfer']['sandwichId'].unique().tolist()\n",
    "diff_signer_sandwiches_with_transfer = sandwich_stat[sandwich_stat['sandwichId'].isin(diff_signer_sandwiches_with_transfer_list)]\n",
    "print(f\"\\nNumber of sandwiches using transfer: {len(diff_signer_sandwiches_with_transfer_list)}\")\n",
    "print(f\"Profit of transfer sandwiches: {diff_signer_sandwiches_with_transfer['profit_in_usd'].sum()}\")\n",
    "\n",
    "print(f\"\\nTop diff signer sandwiches\")\n",
    "top_diff_signer_attacks = diff_signer_sandwiches.sort_values(by='profit_in_usd', ascending=False).head(10)\n",
    "print_df(top_diff_signer_attacks)\n",
    "\n",
    "print(f\"\\nTop diff signer transfer sandwiches\")\n",
    "top_transfer_attacks = diff_signer_sandwiches_with_transfer.sort_values(by='profit_in_usd', ascending=False).head(10)\n",
    "print_df(top_transfer_attacks)\n",
    "\n",
    "# 2. Multi-front/backrunning\n",
    "multi_fb_sandwiches = sandwich_stat[(sandwich_stat['fr_count'] > 1) | (sandwich_stat['br_count'] > 1)]\n",
    "print(f\"\\nNumber of sandwiches utilizing multi-fb: {len(multi_fb_sandwiches)} ({len(multi_fb_sandwiches) / len(sandwich_stat):.2f})\")\n",
    "print(f\"Atomic: {len(multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] == 'inblock_consec'])}, Profit: {multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] == 'inblock_consec']['profit_in_usd'].sum()}\")\n",
    "print(f\"Non-Atomic: {len(multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] != 'inblock_consec'])}, Profit: {multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] != 'inblock_consec']['profit_in_usd'].sum()}\")\n",
    "print(f\"\\tCross Block: {len(multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] == 'cross_block'])}, Profit: {multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] == 'cross_block']['profit_in_usd'].sum()}\")\n",
    "print(f\"\\tIn-Block: {len(multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] == 'inblock_non_consec'])}, Profit: {multi_fb_sandwiches[multi_fb_sandwiches['distance_type'] == 'inblock_non_consec']['profit_in_usd'].sum()}\")\n",
    "print(f\"Total Profit: {multi_fb_sandwiches['profit_in_usd'].sum()}\")\n",
    "\n",
    "print(f\"\\nTop multi-fb sandwiches\")\n",
    "top_multi_fb_attacks = multi_fb_sandwiches.sort_values(by='profit_in_usd', ascending=False).head(10)\n",
    "print_df(multi_fb_sandwiches, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jito Usage\n",
    "bundle_sandwich = sandwich_stat[\n",
    "    (sandwich_stat['bundle_status']=='all') \n",
    "]\n",
    "non_bundle_sandwich = sandwich_stat[\n",
    "    (sandwich_stat['bundle_status']!='all') \n",
    "]\n",
    "\n",
    "consec_bundle_sandwich = bundle_sandwich[\n",
    "    (bundle_sandwich['distance_type']=='inblock_consec') & \n",
    "    (bundle_sandwich['bundle_status']=='all')\n",
    "]\n",
    "\n",
    "non_consec_bundle_sandwich = bundle_sandwich[\n",
    "    (bundle_sandwich['distance_type']!='inblock_consec') & \n",
    "    (bundle_sandwich['bundle_status']=='all')\n",
    "]\n",
    "\n",
    "print(f\"\\nNumber of Non-Jito sandwiches: {len(non_bundle_sandwich)}\")\n",
    "print(f\"\\nNon-jito Max Loss: {non_bundle_sandwich['profit_in_usd'].min()}\")\n",
    "print(f\"Non-jito Max Profit: {non_bundle_sandwich['profit_in_usd'].max()}\")\n",
    "print(f\"Non-jito Average Profit: {non_bundle_sandwich['profit_in_usd'].mean()}\")\n",
    "print(f\"Non-jito Median Profit: {non_bundle_sandwich['profit_in_usd'].median()}\")\n",
    "\n",
    "print(f\"\\nNumber of Jito sandwiches: {len(bundle_sandwich)}\")\n",
    "print(f\"Share in all sandwiches: {len(bundle_sandwich)/len(sandwich_stat):.2f}\")\n",
    "print(f\"Total Profit: {bundle_sandwich['profit_in_usd'].sum()}\")\n",
    "print(f\"Average Profit: {bundle_sandwich['profit_in_usd'].mean()}\")\n",
    "print(f\"Jito Max Loss: {bundle_sandwich['profit_in_usd'].min()}\")\n",
    "print(f\"Jito Max Profit: {bundle_sandwich['profit_in_usd'].max()}\")\n",
    "\n",
    "print(f\"\\nNumber of consecutive Jito sandwiches: {len(consec_bundle_sandwich)} / {len(atomic_sandwiches)} ({len(consec_bundle_sandwich) / len(atomic_sandwiches)})\")\n",
    "print(f\"Share in all sandwiches: {len(consec_bundle_sandwich)/len(sandwich_stat):.2f}\")\n",
    "print(f\"Total Profit: {consec_bundle_sandwich['profit_in_usd'].sum()}\")\n",
    "print(f\"Average Profit: {consec_bundle_sandwich['profit_in_usd'].mean()}\")\n",
    "print(f\"Jito Max Loss: {consec_bundle_sandwich['profit_in_usd'].min()}\")\n",
    "print(f\"Jito Max Profit: {consec_bundle_sandwich['profit_in_usd'].max()}\")\n",
    "\n",
    "print(f\"\\nNumber of non-consecutive Jito sandwiches: {len(non_consec_bundle_sandwich)} / {len(non_atomic_sandwiches)} ({len(non_consec_bundle_sandwich) / len(non_atomic_sandwiches)})\")\n",
    "print(f\"Share in all sandwiches: {len(non_consec_bundle_sandwich)/len(sandwich_stat):.2f}\")\n",
    "print(f\"Total Profit: {non_consec_bundle_sandwich['profit_in_usd'].sum()}\")\n",
    "print(f\"Average Profit: {non_consec_bundle_sandwich['profit_in_usd'].mean()}\")\n",
    "print(f\"Max Loss: {non_consec_bundle_sandwich['profit_in_usd'].max()}\")\n",
    "\n",
    "print(f\"\\nAverage victim count per Jito sandwich: {bundle_sandwich['victim_count'].mean()}\")\n",
    "print(f\"Average victim count per Non-Jito sandwich: {non_bundle_sandwich['victim_count'].mean()}\")\n",
    "\n",
    "win_bundle_sandwich = bundle_sandwich[bundle_sandwich['profitA']>=0]\n",
    "print(f\"\\nJito Sandwich Win Rate: {len(win_bundle_sandwich)/len(bundle_sandwich)*100:.2f}\")\n",
    "small_loss_bundle_sandwich = bundle_sandwich[(bundle_sandwich['profitA']<0) & (bundle_sandwich['profit_in_usd']>=-1e-3)]\n",
    "print(f\"Small loss bundle sandwich share: {len(small_loss_bundle_sandwich)/len(bundle_sandwich)*100:.2f}\")\n",
    "print(f\"Small loss bundle sandwich share in losed sandwich: {len(small_loss_bundle_sandwich)/len(bundle_sandwich[bundle_sandwich['profitA']<0])*100:.2f}\")\n",
    "\n",
    "win_consec_bundle_sandwich = consec_bundle_sandwich[consec_bundle_sandwich['profitA']>=0]\n",
    "print(f\"\\nConsec ito Sandwich Win Rate: {len(win_consec_bundle_sandwich)/len(consec_bundle_sandwich)*100:.2f}\")\n",
    "small_loss_consec_bundle_sandwich = consec_bundle_sandwich[(consec_bundle_sandwich['profitA']<0) & (consec_bundle_sandwich['profit_in_usd']>=-1e-3)]\n",
    "print(f\"Small loss bundle sandwich share: {len(small_loss_consec_bundle_sandwich)/len(consec_bundle_sandwich)*100:.2f}\")\n",
    "print(f\"Small loss bundle sandwich share in losed sandwich: {len(small_loss_consec_bundle_sandwich)/len(consec_bundle_sandwich[consec_bundle_sandwich['profitA']<0])*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "jito_sandwich_stat = sandwich_stat[\n",
    "    ((sandwich_stat['bundle_status'] == 'all') &\n",
    "    (sandwich_stat['distance_type'] == 'inblock_consec'))\n",
    "].copy()\n",
    "\n",
    "all_sandwich_stat = sandwich_stat.copy()\n",
    "\n",
    "distance_bins = [-float('inf'), -10, -1, -1e-3, 0, 1e-3, 1, 10, float('inf')]\n",
    "distance_labels = [\n",
    "    r\"$\\leq -10$\",\n",
    "    r\"$-10\\sim-1$\",\n",
    "    r\"$-1\\sim -10^{-3}$\",\n",
    "    r\"$-10^{-3}\\sim 0$\",\n",
    "    r\"$0\\sim 10^{-3}$\",\n",
    "    r\"$10^{-3}\\sim 1$\",\n",
    "    r\"$1\\sim10$\",\n",
    "    r\"$\\geq 10$\"\n",
    "]\n",
    "\n",
    "for df in [jito_sandwich_stat, all_sandwich_stat]:\n",
    "    df['profit_bin'] = pd.cut(\n",
    "        df['profit_in_usd'],\n",
    "        bins=distance_bins,\n",
    "        labels=distance_labels,\n",
    "        right=False\n",
    "    )\n",
    "\n",
    "grouped_jito = jito_sandwich_stat.groupby('profit_bin')['profit_in_usd'].agg(\n",
    "    volume='count',\n",
    "    total_profit='sum'\n",
    ").reset_index()\n",
    "print_df(grouped_jito)\n",
    "\n",
    "grouped_all = all_sandwich_stat.groupby('profit_bin')['profit_in_usd'].agg(\n",
    "    volume='count',\n",
    "    total_profit='sum'\n",
    ").reset_index()\n",
    "print_df(grouped_all)\n",
    "\n",
    "labels = distance_labels\n",
    "grouped_jito = grouped_jito.set_index(grouped_jito['profit_bin'].astype(str))\n",
    "grouped_all = grouped_all.set_index(grouped_all['profit_bin'].astype(str))\n",
    "jito_vol = grouped_jito['volume'].reindex(labels).fillna(0).values\n",
    "all_vol = grouped_all['volume'].reindex(labels).fillna(0).values\n",
    "jito_profit = grouped_jito['total_profit'].reindex(labels).fillna(0).values\n",
    "all_profit = grouped_all['total_profit'].reindex(labels).fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424206e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.bar(labels, jito_vol, color=\"#87AAB9\", alpha=0.8, label=\"Volume\")\n",
    "ax2.plot(labels, jito_profit, color=\"#2F5763\", marker='o', linewidth=2.5,\n",
    "         markersize=7, label=\"Profit (USD)\")\n",
    "\n",
    "# ax1.set_title(\"Jito Bundle\", fontsize=16)\n",
    "ax1.set_xlabel(\"Profit Range (USD)\", fontsize=16)\n",
    "ax1.set_ylabel(\"Sandwich Volume\", fontsize=16)\n",
    "ax2.set_ylabel(\"Total Profit (USD)\", fontsize=16)\n",
    "\n",
    "# Use log-scale-like spacing for Volume with zero line placed slightly below the center\n",
    "y1_max = jito_vol.max()\n",
    "ax1.set_ylim(bottom=-y1_max*0.2, top=y1_max * 1.1)\n",
    "\n",
    "# Symmetric bounds for the Profit axis with sparse ticks\n",
    "y2_max = abs(jito_profit).max()\n",
    "ax2.set_ylim(-y2_max * 0.2, y2_max * 1.1)\n",
    "ax2.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax2.axhline(0, color='gray', linewidth=1.2, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Grid and legend settings\n",
    "ax1.grid(axis='both', linestyle='--', alpha=0.4)\n",
    "ax2.grid(axis='both', linestyle='-', alpha=0)\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=14)\n",
    "ax1.tick_params(axis='x', labelrotation=25, labelsize=12)\n",
    "ax1.tick_params(axis='y', labelsize=14)\n",
    "ax2.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "for spine in ax1.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data/jito_plot.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Second figure: Non-JITO\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.bar(labels, all_vol, color=\"#A8D5BA\", alpha=0.8, label=\"Volume\")\n",
    "ax2.plot(labels, all_profit, color=\"#3C6F4A\", marker='s', linewidth=2.5,\n",
    "         markersize=7, label=\"Profit (USD)\")\n",
    "\n",
    "ax1.set_xlabel(\"Profit Range (USD)\", fontsize=16)\n",
    "ax1.set_ylabel(\"Sandwich Volume\", fontsize=16)\n",
    "ax2.set_ylabel(\"Total Profit (USD)\", fontsize=16)\n",
    "\n",
    "# Use log-scale-like spacing for Volume with zero line placed slightly below the center\n",
    "y1_max = all_vol.max()\n",
    "ax1.set_ylim(bottom=-y1_max*0.6, top=y1_max * 1.1)\n",
    "\n",
    "# Symmetric bounds for the Profit axis with sparse ticks\n",
    "y2_max = max(abs(all_profit.max()), abs(all_profit.min()))\n",
    "ax2.set_ylim(-y2_max*0.6, y2_max * 1.1)\n",
    "ax2.yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "ax2.axhline(0, color='gray', linewidth=1.2, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Grid and legend settings\n",
    "ax1.grid(axis='both', linestyle='--', alpha=0.4)\n",
    "ax2.grid(axis='both', linestyle='-', alpha=0)\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=14)\n",
    "ax1.tick_params(axis='x', labelrotation=25, labelsize=12)\n",
    "ax1.tick_params(axis='y', labelsize=14)\n",
    "ax2.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "for spine in ax1.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data/nonjito_plot.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(\"data/sandwich_bundle_parquet/*.parquet\")\n",
    "jito_fee = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)\n",
    "jito_fee['totalLandedTipLamports'] /= 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "\n",
    "sandwich_stat['timestamp'] = pd.to_datetime(sandwich_stat['timestamp'], errors='coerce')\n",
    "sandwich_stat[\"date_bucket\"] = sandwich_stat[\"timestamp\"].dt.floor(f\"{1}D\")\n",
    "sandwich_stat['date_bucket'] = pd.to_datetime(sandwich_stat['date_bucket'])\n",
    "\n",
    "atomic = sandwich_stat[sandwich_stat['distance_type'] == 'inblock_consec'].copy()\n",
    "non_atomic = sandwich_stat[sandwich_stat['distance_type'] != 'inblock_consec'].copy()\n",
    "\n",
    "for df in [atomic, non_atomic]:\n",
    "    df['avg_fr_fee'] = df['fr_fee'] / df['fr_count'].replace(0, pd.NA) / 1e9\n",
    "    df['avg_br_fee'] = df['br_fee'] / df['br_count'].replace(0, pd.NA) / 1e9\n",
    "\n",
    "atomic_daily = (\n",
    "    atomic.groupby('date_bucket', as_index=False)[['avg_fr_fee', 'avg_br_fee']]\n",
    "    .mean()\n",
    "    .rename(columns={'avg_fr_fee': 'atomic_fr_fee', 'avg_br_fee': 'atomic_br_fee'})\n",
    ")\n",
    "non_atomic_daily = (\n",
    "    non_atomic.groupby('date_bucket', as_index=False)[['avg_fr_fee', 'avg_br_fee']]\n",
    "    .mean()\n",
    "    .rename(columns={'avg_fr_fee': 'non_atomic_fr_fee', 'avg_br_fee': 'non_atomic_br_fee'})\n",
    ")\n",
    "df_fee_daily = atomic_daily.merge(non_atomic_daily, on='date_bucket', how='outer').sort_values('date_bucket')\n",
    "\n",
    "# total cost data (tip + tx fee)\n",
    "atomic = atomic.merge(jito_fee[['sandwichId', 'totalLandedTipLamports']], on='sandwichId', how='left')\n",
    "atomic['totalLandedTipLamports'] = atomic['totalLandedTipLamports'].fillna(0)\n",
    "atomic['fr_fee'] /= 1e9\n",
    "atomic['br_fee'] /= 1e9\n",
    "atomic['total_cost'] = atomic['fr_fee'] + atomic['br_fee'] + atomic['totalLandedTipLamports']\n",
    "\n",
    "non_atomic = non_atomic.merge(jito_fee[['sandwichId', 'totalLandedTipLamports']], on='sandwichId', how='left')\n",
    "non_atomic['totalLandedTipLamports'] = non_atomic['totalLandedTipLamports'].fillna(0)\n",
    "non_atomic['fr_fee'] /= 1e9\n",
    "non_atomic['br_fee'] /= 1e9\n",
    "non_atomic['total_cost'] = non_atomic['fr_fee'] + non_atomic['br_fee'] + non_atomic['totalLandedTipLamports']\n",
    "\n",
    "atomic['timestamp'] = pd.to_datetime(atomic['timestamp'], errors='coerce')\n",
    "atomic[\"date_bucket\"] = atomic[\"timestamp\"].dt.floor(f\"{1}D\")\n",
    "non_atomic['timestamp'] = pd.to_datetime(non_atomic['timestamp'], errors='coerce')\n",
    "non_atomic[\"date_bucket\"] = non_atomic[\"timestamp\"].dt.floor(f\"{1}D\")\n",
    "\n",
    "atomic_daily_cost = (\n",
    "    atomic.groupby('date_bucket', as_index=False)[['total_cost']]\n",
    "    .mean()\n",
    "    .rename(columns={'total_cost': 'atomic_total_cost'})\n",
    ")\n",
    "non_atomic_daily_cost = (\n",
    "    non_atomic.groupby('date_bucket', as_index=False)[['total_cost']]\n",
    "    .mean()\n",
    "    .rename(columns={'total_cost': 'non_atomic_total_cost'})\n",
    ")\n",
    "df_cost_daily = atomic_daily_cost.merge(non_atomic_daily_cost, on='date_bucket', how='outer').sort_values('date_bucket')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "colors = {\n",
    "    'atomic_fr': '#1b4f72',      \n",
    "    'atomic_br': '#5dade2',      \n",
    "    'non_atomic_fr': '#922b21',  \n",
    "    'non_atomic_br': '#ec7063',  \n",
    "    'atomic_total': '#1b4f72',\n",
    "    'non_atomic_total': '#922b21'\n",
    "}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,10), sharex=True)\n",
    "\n",
    "# Upper Figure\n",
    "ax1.plot(df_fee_daily['date_bucket'], df_fee_daily['atomic_fr_fee'], color=colors['atomic_fr'],\n",
    "         label='Consecutive sandwich frontrun', linewidth=2.2)\n",
    "ax1.plot(df_fee_daily['date_bucket'], df_fee_daily['atomic_br_fee'], color=colors['atomic_br'],\n",
    "         label='Consecutive sandwich backrun', linewidth=2.2)\n",
    "ax1.plot(df_fee_daily['date_bucket'], df_fee_daily['non_atomic_fr_fee'], color=colors['non_atomic_fr'],\n",
    "         label='Non-consecutive sandwich frontrun', linewidth=2.2)\n",
    "ax1.plot(df_fee_daily['date_bucket'], df_fee_daily['non_atomic_br_fee'], color=colors['non_atomic_br'],\n",
    "         label='Non-consecutive sandwich backrun', linewidth=2.2)\n",
    "ax1.set_ylabel('Average Transaction Fee (SOL)', fontsize=16)\n",
    "ax1.legend(fontsize=14, frameon=False, loc='upper right')\n",
    "\n",
    "ax1.grid(True, linestyle='--', color='gray', alpha=0.6, linewidth=0.6)\n",
    "ax1.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax1.tick_params(axis='both', labelsize=14, rotation=30)\n",
    "for spine in ax1.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1.2)\n",
    "\n",
    "# Lower figure\n",
    "ax2.plot(df_cost_daily['date_bucket'], df_cost_daily['atomic_total_cost'], color=colors['atomic_total'],\n",
    "         label='Consecutive sandwich', linewidth=2.2)\n",
    "ax2.plot(df_cost_daily['date_bucket'], df_cost_daily['non_atomic_total_cost'], color=colors['non_atomic_total'],\n",
    "         label='Non-consecutive sandwich', linewidth=2.2)\n",
    "ax2.set_ylabel('Average Cost (SOL)', fontsize=16)\n",
    "ax2.legend(fontsize=16, frameon=False, loc='upper right')\n",
    "\n",
    "ax2.grid(True, linestyle='--', color='gray', alpha=0.6, linewidth=0.6)\n",
    "ax2.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax2.tick_params(axis='both', labelsize=14, rotation=30)\n",
    "for spine in ax2.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1.2)\n",
    "\n",
    "ax2.xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\"))\n",
    "plt.xticks(rotation=30, fontsize=13)\n",
    "plt.tight_layout(h_pad=2)\n",
    "\n",
    "plt.savefig('data/daily_fee_cost_subplots.pdf', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker_summary = pd.read_csv('data/attacker_summary.csv')\n",
    "\n",
    "print(f\"\\nTotal identified attackers: {len(attacker_summary)}\")\n",
    "print(f\"Total profit: {attacker_summary['total_profit_in_usd'].sum()}\")\n",
    "print(f\"Total sandwich: {attacker_summary['sandwich_count'].sum()}\")\n",
    "print(f\"Average Profit per Attacker: {attacker_summary['total_profit_in_usd'].sum()/len(attacker_summary):.2f}\")\n",
    "\n",
    "major_attacker = attacker_summary[attacker_summary['sandwich_count']>100]\n",
    "print(f\"\\nTotal major attackers: {len(major_attacker)}\")\n",
    "print(f\"Total profit: {major_attacker['total_profit_in_usd'].sum()}\")\n",
    "print(f\"Total sandwich: {major_attacker['sandwich_count'].sum()}\")\n",
    "print(f\"Average Profit per Attacker: {major_attacker['total_profit_in_usd'].sum()/len(major_attacker):.2f}\")\n",
    "\n",
    "high_profit_attacker = major_attacker[major_attacker['win_rate']>=0.9]\n",
    "print(f\"\\nTotal high profit attackers: {len(high_profit_attacker)}\")\n",
    "print(f\"Total profit: {high_profit_attacker['total_profit_in_usd'].sum()} ({high_profit_attacker['total_profit_in_usd'].sum() / attacker_summary['total_profit_in_usd'].sum()*100:.3f})\")\n",
    "print(f\"Total sandwich: {high_profit_attacker['sandwich_count'].sum()}\")\n",
    "print(f\"Average Profit per Attacker: {high_profit_attacker['total_profit_in_usd'].sum()/len(high_profit_attacker):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTop attackers: \")\n",
    "print_df(high_profit_attacker.sort_values(by='total_profit_in_usd', ascending=False), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Filter attacker transactions\n",
    "program_view = sandwiches_txs.copy()\n",
    "program_view = program_view[program_view[\"type\"].isin(ATTACKER_TX_TYPES)]\n",
    "program_view['programs'] = program_view['programs'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Build signer → attacker_key mapping table\n",
    "attacker_summary['signer_addresses'] = attacker_summary['signer_addresses'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "signer_to_attacker = (\n",
    "    attacker_summary[['attacker_key', 'signer_addresses']]\n",
    "    .explode('signer_addresses')\n",
    "    .rename(columns={'signer_addresses': 'signer'})\n",
    ")\n",
    "print_df(signer_to_attacker)\n",
    "\n",
    "# Merge attacker info\n",
    "program_view = program_view.merge(signer_to_attacker, on='signer', how='left')\n",
    "program_view = program_view.merge(\n",
    "    sandwich_stat[['sandwichId', 'profit_in_usd']], \n",
    "    on='sandwichId', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Explode program list into multiple rows\n",
    "program_view_explode = program_view.explode('programs')\n",
    "program_view_explode = program_view_explode.dropna(subset=['programs'])\n",
    "\n",
    "# Count unique sandwiches per program\n",
    "program_to_unique_sandwich = (\n",
    "    program_view_explode.groupby('programs')['sandwichId']\n",
    "    .nunique()\n",
    "    .reset_index(name='unique_sandwich_count')\n",
    ")\n",
    "\n",
    "# Count unique transactions per program\n",
    "program_to_unique_transaction = (\n",
    "    program_view_explode.groupby('programs')['signature']\n",
    "    .nunique()\n",
    "    .reset_index(name='unique_tx_count')\n",
    ")\n",
    "\n",
    "# Count unique attackers per program\n",
    "program_to_unique_attacker = (\n",
    "    program_view_explode.groupby('programs')['attacker_key']\n",
    "    .nunique()\n",
    "    .reset_index(name='unique_attacker_count')\n",
    ")\n",
    "\n",
    "# Sum total profit per program\n",
    "program_total_profit = (\n",
    "    program_view_explode.groupby('programs')['profit_in_usd']\n",
    "    .sum()\n",
    "    .reset_index(name='total_profit_usd')\n",
    ")\n",
    "\n",
    "# Combine all program-level statistics\n",
    "program_stats = (\n",
    "    program_to_unique_sandwich\n",
    "    .merge(program_to_unique_attacker, on='programs', how='outer')\n",
    "    .merge(program_total_profit, on='programs', how='outer')\n",
    "    .merge(program_to_unique_transaction, on='programs', how='outer')\n",
    "    .sort_values(by='unique_sandwich_count', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_stats['sandwich_share'] = program_stats['unique_sandwich_count'] / len(sandwich_stat)\n",
    "program_stats['attacker_share'] = program_stats['unique_attacker_count'] / len(attacker_summary)\n",
    "print_df(program_stats.sort_values(by='unique_tx_count', ascending=False), 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
